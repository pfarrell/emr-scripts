# EMR Scripts

A collection of shell scripts designed for a simple EMR workflow.
This has not been tested under another user's account, so, caveat emptor.

These emr hive jobs flows are designed to launch a cluster to analyze a time slice of data
and store that crunched data in csv format on s3 (where it can be put into mysql or excel
or pandas or r or whatnot

### deploy.sh
deploys a script to s3 (for later use under a hive job)
### get_logs.sh ([job id] | last)
retrieves logs generated by a job flow
### get_data.sh
syncs generated data from s3://hadoop.output/ to local system
### start-job.sh
starts a job with arguments



#### Dependencies
* [elastic-mapreduce-ruby](https://github.com/tc/elastic-mapreduce-ruby)
* [s3cmd](https://github.com/s3tools/s3cmd)

#####ENV Variables
|name|value|
|---|---|
|HIVE_SCRIPT_DIR|S3 path where scripts are deployed|
|HADOOP_OUTPUT_DIR|S3 path where script outputs are placed|
|HADOOP_LOG_DIR|S3 path where EMR job logs are placed|
